---
title: "Data Journalism Lesson 8: Data Smells"
output: 
  learnr::tutorial:
    progressive: true
    allow_skip: true
    theme: journal
    ace_theme: github
runtime: shiny_prerendered
description: >
  Stop a wrong story before it starts.
---

```{r setup, include=FALSE}
library(learnr)
library(gradethis)
library(tidyverse)
library(glue)
library(lubridate)
knitr::opts_chunk$set(echo = FALSE)
tutorial_options(exercise.completion=FALSE)
```
```{r load-data, message=FALSE, warning=FALSE}
state <- Sys.getenv("tutorial.state")

stateName <- read_csv("https://the-art-of-data-journalism.github.io/tutorial-data/states.csv") |> filter(Postal == state) 

stateName <- stateName |> 
  mutate(dataurl = case_when(
    Postal == "AL" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/plane-crashes/", str_to_lower(State), ".csv"),
    Postal == "AK" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/plane-crashes/", str_to_lower(State), ".csv"),
    Postal == "AZ" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/plane-crashes/", str_to_lower(State), ".csv"),
    Postal == "AR" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/plane-crashes/", str_to_lower(State), ".csv"),
    Postal == "CA" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/plane-crashes/", str_to_lower(State), ".csv"),
    Postal == "CO" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/plane-crashes/", str_to_lower(State), ".csv"),
    Postal == "CT" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/plane-crashes/", str_to_lower(State), ".csv"),
    Postal == "DE" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/plane-crashes/", str_to_lower(State), ".csv"),
    Postal == "FL" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/plane-crashes/", str_to_lower(State), ".csv"),
    Postal == "GA" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/plane-crashes/", str_to_lower(State), ".csv"),
    Postal == "HI" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/plane-crashes/", str_to_lower(State), ".csv"),
    Postal == "ID" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/plane-crashes/", str_to_lower(State), ".csv"),
    Postal == "IL" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/plane-crashes/", str_to_lower(State), ".csv"),
    Postal == "IN" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/plane-crashes/", str_to_lower(State), ".csv"),
    Postal == "IA" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/plane-crashes/", str_to_lower(State), ".csv"),
    Postal == "KS" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/plane-crashes/", str_to_lower(State), ".csv"),
    Postal == "KY" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/plane-crashes/", str_to_lower(State), ".csv"),
    Postal == "LA" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/plane-crashes/", str_to_lower(State), ".csv"),
    Postal == "ME" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/plane-crashes/", str_to_lower(State), ".csv"),
    Postal == "MD" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/plane-crashes/", str_to_lower(State), ".csv"),
    Postal == "MA" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/plane-crashes/", str_to_lower(State), ".csv"),
    Postal == "MI" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/plane-crashes/", str_to_lower(State), ".csv"),
    Postal == "MN" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/plane-crashes/", str_to_lower(State), ".csv"),
    Postal == "MS" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/plane-crashes/", str_to_lower(State), ".csv"),
    Postal == "MO" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/plane-crashes/", str_to_lower(State), ".csv"),
    Postal == "MT" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/plane-crashes/", str_to_lower(State), ".csv"),
    Postal == "NE" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/plane-crashes/", str_to_lower(State), ".csv"),
    Postal == "NV" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/plane-crashes/", str_to_lower(State), ".csv"),
    Postal == "NH" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/plane-crashes/", str_to_lower(State), ".csv"),
    Postal == "NJ" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/plane-crashes/", str_to_lower(State), ".csv"),
    Postal == "NM" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/plane-crashes/", str_to_lower(State), ".csv"),
    Postal == "NY" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/plane-crashes/", str_to_lower(State), ".csv"),
    Postal == "NC" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/plane-crashes/", str_to_lower(State), ".csv"),
    Postal == "ND" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/plane-crashes/", str_to_lower(State), ".csv"),
    Postal == "OH" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/plane-crashes/", str_to_lower(State), ".csv"),
    Postal == "OK" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/plane-crashes/", str_to_lower(State), ".csv"),
    Postal == "OR" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/plane-crashes/", str_to_lower(State), ".csv"),
    Postal == "PA" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/plane-crashes/", str_to_lower(State), ".csv"),
    Postal == "RI" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/plane-crashes/", str_to_lower(State), ".csv"),
    Postal == "SC" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/plane-crashes/", str_to_lower(State), ".csv"),
    Postal == "SD" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/plane-crashes/", str_to_lower(State), ".csv"),
    Postal == "TN" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/plane-crashes/", str_to_lower(State), ".csv"),
    Postal == "TX" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/plane-crashes/", str_to_lower(State), ".csv"),
    Postal == "UT" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/plane-crashes/", str_to_lower(State), ".csv"),
    Postal == "VT" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/plane-crashes/", str_to_lower(State), ".csv"),
    Postal == "VA" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/plane-crashes/", str_to_lower(State), ".csv"),
    Postal == "WA" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/plane-crashes/", str_to_lower(State), ".csv"),
    Postal == "WV" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/plane-crashes/", str_to_lower(State), ".csv"),
    Postal == "WI" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/plane-crashes/", str_to_lower(State), ".csv"),
    Postal == "WY" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/plane-crashes/", str_to_lower(State), ".csv"),
    TRUE ~ "https://the-art-of-data-journalism.github.io/tutorial-data/plane-crashes/nebraska.csv"  # Default case if none match
  ))

crashes <- read_csv(stateName$dataurl)

countyLanguage <- case_when(
  state == "AK" ~ c("county equivalent", "county equivalents"),
  state == "CT" ~ c("planning region", "planning regions"),
  state == "LA" ~ c("parish", "parishes"),
  state == "VA" ~ c("county or city", "counties or cities"),
  TRUE ~ c("county", "counties")
)

nrows <- nrow(crashes)
ncolumns <- ncol(crashes)
```
## The Goal

In this lesson, you'll learn about the critical concept of "data smells" - common issues and inconsistencies that can arise in datasets. By the end of this tutorial, you'll understand how to conduct an initial assessment of a dataset to identify potential problems like missing data, wrong data types, gaps in data, and internal inconsistencies. You'll practice using R functions like glimpse(), group_by(), and tally() to explore your data systematically. This skill is essential for data journalists to ensure the accuracy and reliability of their analyses before drawing any conclusions.

## What is Data Journalism?

Chad Day, the chief elections analyst at the Associated Press, starts every data analysis he does with what amounts to a fight. 

"I think that I always look at the data as it's going to try to trick me. And I have to find all of the tricks that it's going to throw at me," he said. "And then I play to the strengths, right? Because you're going to identify a bunch of weaknesses that are in the data. And you don't want to base your analysis on those weaknesses unless your story is about the weaknesses in the data."

So what does he -- and many other data analysts -- do? You've heard of giving something the smell test, yes? This is the very nerdy equivalent of the smell test. We call them data smells.

"Every single time we use data, we have to do the basic checks. And that means that we run those basic things every single time," Day said. "And it should be part of your muscle memory."

What's a data smell test? 

"Let's use an example," Day said. "It's 50 state data. I make sure that all 50 states are in there, right? I make sure that if there are additional-- like if it's 51 or 52, is DC included?"

Any time you are given a dataset from anyone, you should immediately be suspicious. Is this data what I think it is? Does it include what I expect? Is there anything I need to know about it? Will it produce the information I expect?

Failure to give data the smell test [can lead you to miss stories and get your butt kicked on a competitive story](https://source.opennews.org/en-US/learning/handling-data-about-race-and-ethnicity/).

Giving your data the smell test isn't new. Exploratory Data Analysis or EDA has been around for a long time -- John Tukey started pushing the idea in 1970 and wrote the text that would lay the groundwork for generations of data analysts in 1977 (I have a copy in my office!). But EDA treats data in an almost neutral way - it's almost naive. Data smells treat data with skepticism and distrust. With data smells, we're trying to find common mistakes in data because we have to know if they are there. [For more on data smells, read the GitHub wiki post that started it all](https://github.com/nikeiubel/data-smells/wiki/Ensuring-Accuracy-in-Data-Journalism). The common mistakes we're looking for are:

-   Missing data
-   Gaps in data
-   Wrong type of data
-   Outliers
-   Sharp curves
-   Conflicting information within a dataset
-   Conflicting information across datasets
-   Wrongly derived data
-   Internal inconsistency
-   External inconsistency
-   Wrong spatial data
-   Unusable data, including non-standard abbreviations, ambiguous data, extraneous data, inconsistent data

Not all of these data smells are detectable in code. You may have to ask people about the data. You may have to compare it to another dataset yourself. Does the agency that uses the data produce reports from the data? Does your analysis match those reports? That will expose wrongly derived data, or wrong units, or mistakes you made with inclusion or exclusion.

But many of them are, and they are easy, knowing what you already know. You just need a little code, a dollop of logic and a healthy skepticism that the data you have is good. 

## The Basics

Every dataset has quirks that make certain kinds of analysis annoyingly difficult. For example, the State of Nebraska publishes a dataset of every currently incarcerated person in the state prison system. A question that might come up in news stories -- how many people are currently serving prison time for certain crimes? For example: Meth related crimes. The problem? There's several dozen unique ways that the state has recorded possession of methamphetamine. Different spellings, different abbreviations, meth for short, methamphetamine spelled out, odd ways of abbreviating possession. It would take months of work to fix all the different ways the state has recorded a meth-related crime. And would it be worth doing that work for a single sentence of a story? Not likely.

But some can be fixed quicker. But you won't know what needs fixed -- or even if your data is worth using -- until you give your data the smell test.

Let's work on some examples the NTSB plane crash data, which we used in the last exercise. 

First we'll need the Tidyverse and lubridate. Your first step is always loading libraries and you'll need to run this step in nearly every single thing you do.

```{r load-tidyverse, exercise=TRUE}
library(tidyverse)
library(lubridate)
```
```{r load-tidyverse-solution}
library(tidyverse)
library(lubridate)
```
```{r load-tidyverse-check}
grade_this_code()
```

Now import the data.

```{r read, exercise=TRUE, exercise.reveal_solution = FALSE, exercise.setup = "load-data"}
crashes <- read_csv("https://the-art-of-data-journalism.github.io/tutorial-data/plane-crashes/____.csv")
```

```{r read-check}
grade_this({
  if (identical(nrow(.result), nrows)) {
    pass("Great work! You imported your state's plane crashes.")
  }
  fail()
})
```

Now, let's take a look at where this data has flaws.

## Wrong Type

First, let's look at the **Wrong Type Of Data** problem. We can sniff that out by looking at the output of `glimpse`

### Exercise 1: Using glimpse for more than column names

```{r glimpse-data, exercise=TRUE, exercise.setup = "load-data"}
glimpse(____)
```
```{r glimpse-data-solution, exercise.reveal_solution = FALSE}
glimpse(crashes)
```
```{r glimpse-data-check}
grade_this_code()
```

First things first: What type of data are all of the columns being imported as? It's important to look at columns you know you are going to use. Or look at columns that -- just looking at their name -- suggest they should be a specific type of data.

In this data, for example, is the `ReportNo` column a number? ReportNo is short for Report Number, so it suggests it should be? But, recall your basics -- if you don't plan to do math on it, then it's not a number. In this case, the column is empty, so the imported data is a `lgl` type -- logical, which is the default when all the data is NA. 

Another example: `FatalInjuryCount` or `SeriousInjuryCount`. Is a count a number? It sure is. If you wanted to know how many people died in plane crashes in your state, you'd want to sum those counts. You can't sum them if they aren't numbers. Are these counts numbers?

One place we can pretend there's a problem -- look at the `first_bad_date` column. What type is that? Compare it to the `EventDate` column. The `EventDate` column is a dttm column, or date time. That means R knows that column is a date and a time together, and will treat it as such. Our `first_bad_date` column is not a date or dttm column. What is it? Would R recognize that as a date? 

## Missing Data

The second smell we can find in code is **missing data**. We can do that through a series of Group By and Count steps. In aggregates, we explicitly used group by and summarize. Here, because this is exploratory, we can use the `tally()` shortcut. 

Let's first look at the `HighestInjuryLevel` column. Is that column consistently filled out?

### Exercise 2: Missing data part 1

```{r tally-data, exercise=TRUE, exercise.setup = "load-data"}
crashes |> 
  group_by(____) |> 
  ____()
```
```{r tally-data-solution, exercise.reveal_solution = FALSE}
crashes |> 
  group_by(HighestInjuryLevel) |> 
  tally()
```
```{r tally-data-check}
grade_this_code()
```

What we're looking for here are answers that don't make sense. One you're looking for are blanks. Another: NA. In many states, there are crashes that have a `HighestInjuryLevel` of None and also NA. What is the difference? Are they the same thing? Are NA cases where the NTSB just doesn't know? If you go where [I got the data](https://www.ntsb.gov/Pages/AviationQueryV2.aspx), there isn't a good answer. You'd probably have to contact the NTSB to find out what the difference is.

What about `AirportName`?

### Exercise 3: Missing data part 2

```{r tally3-data, exercise=TRUE, exercise.setup = "load-data"}
crashes |> 
  group_by(____) |> 
  ____()
```
```{r tally3-data-solution, exercise.reveal_solution = FALSE}
crashes |> 
  group_by(AirportName) |> 
  tally()
```
```{r tally3-data-check}
grade_this_code()
```

What does NA mean here? NA will be the last result in the table. Does it mean the NTSB doesn't know where this happened? Or does it mean the accident didn't happen at an airport? The answer here is that not all plane crashes happen at an airport ... but a lot of them do. So this isn't missing data -- it's blank for a reason.

## Internal inconsistency

Any time you are going to focus on something, you should check it for consistency inside the data set. So let's pretend you want to look at *who makes* the airplanes that crash. To be clear -- this is a bad idea. There are only a small number of manufacturers and counting the number that crashed is no different than looking at cars that crash. Does a lot of Fords and Chevys crashing mean they're unsafe? Or does it mean there's a *lot* of Fords and Chevys on the road in the United States. 

But, to illustrate the problem of internal consistency, we're going to do this. We're going to put the spotlight on the `Make` column. 

### Exercise 4: Are they the same?

```{r consistent-data, exercise=TRUE, exercise.setup = "load-data"}
crashes |> 
  group_by(____) |> 
  ____()
```
```{r consistent-data-solution, exercise.reveal_solution = FALSE}
crashes |> 
  group_by(Make) |> 
  tally()
```
```{r consistent-data-check}
grade_this_code()
```

Every state is going to be different here, but scroll through the first few pages of data. Do you notice anything? For data to be exact, each row must be the same. And by the same I mean EXACTLY the same. For example: CESSNA and Cessna are not the same. Cirrus and CIRRUS DESIGN GROUP are not the same. Piper, PIPER and PIPER AIRCRAFT INC are very much not the same thing in data world. Now, are they in real life? Yes. You and I can figure that out pretty quickly with just a tiny amount of brainpower. But data analysis requires things to be consistent and identical. And this column of data is not internally consistent.

Can you accurately report on the number of accidents involving each manufacturer? Not yet, but you can (more on that soon!).

And that's what Data Smells are designed to do: stop you from going down a bad path.

## The Recap

Throughout this lesson, you've learned how to apply the concept of "data smells" to critically examine a dataset. You've practiced using glimpse() to check for wrong data types, group_by() and tally() to identify missing data and gaps, and explored ways to spot internal inconsistencies in your data. Remember, these initial checks are crucial steps in any data analysis project. They help you understand the limitations of your data and prevent you from drawing incorrect conclusions. Approach new datasets with healthy skepticism and use these techniques to validate your data before proceeding with more in-depth analysis.

## Terms to Know

- Data Smells: Common issues or inconsistencies in datasets that may indicate potential problems.
- Exploratory Data Analysis (EDA): An approach to analyzing datasets to summarize their main characteristics, often using visual methods.
- Wrong Type of Data: When data is imported or stored in an inappropriate format (e.g., dates stored as text).
- Missing Data: Values that are absent from the dataset, often represented as NA in R.
- Gaps in Data: Unexpected breaks or discontinuities in a dataset, often in time-series data.
- Internal Inconsistency: When the same information is represented differently within a dataset (e.g., inconsistent spelling of locations).
- `tally()`: A function in R that counts the number of observations in each group when used with group_by().
- `guess_max`: A parameter in read_csv() that determines how many rows are used to guess column types.
- `floor_date()`: A function from the lubridate package that rounds dates down to a specified unit of time (e.g., month, year).
