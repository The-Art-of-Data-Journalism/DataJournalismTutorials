---
title: "Data Journalism Lesson 9: Janitor"
output: 
  learnr::tutorial:
    progressive: true
    allow_skip: true
    theme: journal
    ace_theme: github
runtime: shiny_prerendered
description: >
  Clean up your data with code.
---
```{r setup, include=FALSE}
library(learnr)
library(gradethis)
library(tidyverse)
library(glue)
library(janitor)
knitr::opts_chunk$set(echo = FALSE)
tutorial_options(exercise.completion=FALSE)
```
```{r load-data, message=FALSE, warning=FALSE}
state <- Sys.getenv("tutorial.state")

stateName <- read_csv("https://the-art-of-data-journalism.github.io/tutorial-data/states.csv") |> filter(Postal == state) 

stateName <- stateName |> 
  mutate(dataurl = case_when(
    Postal == "AL" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/government-census/", str_to_lower(State), ".csv"),
    Postal == "AK" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/government-census/", str_to_lower(State), ".csv"),
    Postal == "AZ" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/government-census/", str_to_lower(State), ".csv"),
    Postal == "AR" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/government-census/", str_to_lower(State), ".csv"),
    Postal == "CA" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/government-census/", str_to_lower(State), ".csv"),
    Postal == "CO" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/government-census/", str_to_lower(State), ".csv"),
    Postal == "CT" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/government-census/", str_to_lower(State), ".csv"),
    Postal == "DE" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/government-census/", str_to_lower(State), ".csv"),
    Postal == "FL" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/government-census/", str_to_lower(State), ".csv"),
    Postal == "GA" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/government-census/", str_to_lower(State), ".csv"),
    Postal == "HI" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/government-census/", str_to_lower(State), ".csv"),
    Postal == "ID" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/government-census/", str_to_lower(State), ".csv"),
    Postal == "IL" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/government-census/", str_to_lower(State), ".csv"),
    Postal == "IN" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/government-census/", str_to_lower(State), ".csv"),
    Postal == "IA" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/government-census/", str_to_lower(State), ".csv"),
    Postal == "KS" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/government-census/", str_to_lower(State), ".csv"),
    Postal == "KY" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/government-census/", str_to_lower(State), ".csv"),
    Postal == "LA" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/government-census/", str_to_lower(State), ".csv"),
    Postal == "ME" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/government-census/", str_to_lower(State), ".csv"),
    Postal == "MD" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/government-census/", str_to_lower(State), ".csv"),
    Postal == "MA" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/government-census/", str_to_lower(State), ".csv"),
    Postal == "MI" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/government-census/", str_to_lower(State), ".csv"),
    Postal == "MN" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/government-census/", str_to_lower(State), ".csv"),
    Postal == "MS" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/government-census/", str_to_lower(State), ".csv"),
    Postal == "MO" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/government-census/", str_to_lower(State), ".csv"),
    Postal == "MT" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/government-census/", str_to_lower(State), ".csv"),
    Postal == "NE" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/government-census/", str_to_lower(State), ".csv"),
    Postal == "NV" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/government-census/", str_to_lower(State), ".csv"),
    Postal == "NH" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/government-census/", str_to_lower(State), ".csv"),
    Postal == "NJ" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/government-census/", str_to_lower(State), ".csv"),
    Postal == "NM" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/government-census/", str_to_lower(State), ".csv"),
    Postal == "NY" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/government-census/", str_to_lower(State), ".csv"),
    Postal == "NC" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/government-census/", str_to_lower(State), ".csv"),
    Postal == "ND" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/government-census/", str_to_lower(State), ".csv"),
    Postal == "OH" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/government-census/", str_to_lower(State), ".csv"),
    Postal == "OK" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/government-census/", str_to_lower(State), ".csv"),
    Postal == "OR" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/government-census/", str_to_lower(State), ".csv"),
    Postal == "PA" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/government-census/", str_to_lower(State), ".csv"),
    Postal == "RI" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/government-census/", str_to_lower(State), ".csv"),
    Postal == "SC" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/government-census/", str_to_lower(State), ".csv"),
    Postal == "SD" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/government-census/", str_to_lower(State), ".csv"),
    Postal == "TN" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/government-census/", str_to_lower(State), ".csv"),
    Postal == "TX" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/government-census/", str_to_lower(State), ".csv"),
    Postal == "UT" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/government-census/", str_to_lower(State), ".csv"),
    Postal == "VT" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/government-census/", str_to_lower(State), ".csv"),
    Postal == "VA" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/government-census/", str_to_lower(State), ".csv"),
    Postal == "WA" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/government-census/", str_to_lower(State), ".csv"),
    Postal == "WV" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/government-census/", str_to_lower(State), ".csv"),
    Postal == "WI" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/government-census/", str_to_lower(State), ".csv"),
    Postal == "WY" ~ paste0("https://the-art-of-data-journalism.github.io/tutorial-data/government-census/", str_to_lower(State), ".csv"),
    TRUE ~ "https://the-art-of-data-journalism.github.io/tutorial-data/government-census/nebraska.csv"  # Default case if none match
  ))

governments <- read_csv(stateName$dataurl)

countyLanguage <- case_when(
  state == "AK" ~ c("county equivalent", "county equivalents"),
  state == "CT" ~ c("planning region", "planning regions"),
  state == "LA" ~ c("parish", "parishes"),
  state == "VA" ~ c("county or city", "counties or cities"),
  TRUE ~ c("county", "counties")
)

nrows <- nrow(governments)
ncolumns <- ncol(governments)

clean_governments <- governments |> 
  clean_names() |> 
  remove_empty(which = c("cols", "rows"))
```

## The Goal

In this lesson, you'll learn how to use the janitor package to clean and standardize your data more efficiently. By the end of this tutorial, you'll understand how to clean column names, remove empty rows and columns, identify duplicates, and explore data consistency using janitor functions. These skills will help you prepare messy datasets for analysis more quickly and reliably, saving you time and reducing errors in your data journalism work.

## What is Data Journalism?

More to come here.

## The Basics

The bane of every data analyst's existence is data cleaning. 

Every developer, every data system, every agency, they all have opinions about how data gets collected. Some decisions make sense from the outside. Some decisions are based entirely on internal politics: who is creating the data, how they are creating it, why they are creating it. Is it automated? Is it manual? Are data normalized -- meaning all the spellings are the same? Are there free form fields where users can just type into or does the system restrict them to choices? 

Your question -- what you want to do with the data -- is almost never part of that equation. 

So cleaning data is the process of fixing issues in your data so you can answer the questions you want to answer. Unfortunately, there's no template here. There's no checklist. It's just a big bag of tricks that eventually runs out and you'll be left fixing individual issues by hand, if it's really bad.

But let's start simple. There are certain tricks that we can start with to make our lives easier. We'll slowly make it harder as we dig deeper.

One of the first places we can clean data is cleaning the headers. Every system has their own way of recording headers, and every developer has their own thoughts of what a good idea is within it. R is most happy when headers are one word, lower case, without special characters. Without telling you, I've been fixing these headers behind the scenes before you get the data. No more. Today, you're going to notice that the `tidyverse` has output columns that have spaces or start with numbers or have special characters in them with backticks around headers. So a column name like Incident Date, is going to look like \`Incident Date\` because of the space. Headers that start with numbers or are just a number -- 2002 -- also get backticks in the `tidyverse`. 

There is an external library in R called `janitor` that makes fixing headers trivially simple. You should already have it, but if you don't, you can install it by running `install.packages("janitor")` in your console. 

First things first, as always: we load the libraries we need. 

```{r load-tidyverse, exercise=TRUE}
library(tidyverse)
library(janitor)
```
```{r load-tidyverse-solution}
library(tidyverse)
library(janitor)
```
```{r load-tidyverse-check}
grade_this_code()
```

Now we load our data. I'm writing this chapter during the last few months of the 2024 Presidential Election. A common task for journalists during elections? Fact-checking. A common trope in elections are claims that government has become too big, too bloated, too expensive. Your first thought, as a reporter, should be simply: Has it? A way to check? The U.S. Census Bureau. The same agency who counts people and estimate populations between counts do a ton of other enumerations in and around American society. One is the annual survey of governments, where the Census Bureau asks every government -- state, county, city, school district -- how many people they employ and what their payroll is. It's a fantastic dataset for comparing your community to others like it, in your state and in the nation. Got a mayoral candidate claiming the city has tripled the number of people working there and is out of control? You can check that. 

We get this data the same way we have all along -- fill in your state, all lowercase letters, dashes for spaces. 

```{r read, exercise=TRUE, exercise.reveal_solution = FALSE, exercise.setup = "load-data"}
governments <- read_csv("https://the-art-of-data-journalism.github.io/tutorial-data/government-census/____.csv")
```

```{r read-check}
grade_this({
  if (identical(nrow(.result), nrows)) {
    pass("Great work! You imported your state's census of governments.")
  }
  fail()
})
```

## Cleaning headers

You can get a sense of the problems with the headers in this data with a quick glimpse -- get it? Glimpse?

```{r glimpse-data, exercise=TRUE, exercise.setup = "load-data"}
glimpse(____)
```
```{r glimpse-data-solution, exercise.reveal_solution = FALSE}
glimpse(governments)
```
```{r glimpse-data-check}
grade_this_code()
```

The second column name tells you a lot of what the problems are. First, notice the backticks. That's the key next to the 1 key on your keyboard. That is not an apostrophe. But you've got a mix of capitals and lowercase and spaces. If you wanted to use this column in a filter, it would look like this: `governments |> filter(\`Type of Government\` == "State")` That's a lot of extra things to go wrong -- did you capitalize correctly, did you use backticks, is that a capital O or lowercase o in the word of? It would be better if we could simplify this and reduce the number of places where we could go wrong.

Janitor makes this easy to fix. How easy? This easy. Janitor has a function called `clean_names()`. That's it. 

### Exercise 1: Cleaning up column names

```{r cleannames-data, exercise=TRUE, exercise.setup = "load-data"}
governments |> _________
```
```{r cleannames-data-solution, exercise.reveal_solution = FALSE}
governments |> clean_names()
```
```{r cleannames-data-check}
grade_this_code()
```

Just like that, all lowercase, all one word, no backticks necessary to confuse our code later on. 

### Exercise 2: Dropping empty columns

Another good trick by janitor is easily dropping empty columns and rows. Sometimes columns are in the data and there's nothing in them. Nada. Blank. Rarer, but still possible: Rows of blank data. We could use `select` and `filter` but janitor reduces the labor involved.

Because this is data from the Census Bureau, an agency who exists to create data, we have a minimum of weirdness to deal with. But a good plan when you begin working with data is to inspect the data after you import it, and then apply `janitor` functions to clean it up. `janitor` has a function called `remove_empty()` where you have to specify which of `rows` or `cols` you want to remove. If they're empty, why have them at all? This won't remove anything, but this is how you would if you needed to:

```{r remove-data, exercise=TRUE, exercise.setup = "load-data"}
governments |> 
  clean_names() |> 
  remove_empty(which = c("c____", "r____"))
```
```{r remove-data-solution, exercise.reveal_solution = FALSE}
governments |> 
  clean_names() |> 
  remove_empty(which = c("cols", "rows"))
```
```{r remove-data-check}
grade_this_code()
```

Let's save what we've done so we can use it for the rest of the exercise into a new dataframe called `clean_governments`.

```{r save-data, exercise=TRUE, exercise.setup = "load-data"}
clean_governments <- governments |> 
  clean_names() |> 
  remove_empty(which = c("cols", "rows"))
```
```{r save-data-solution, exercise.reveal_solution = FALSE}
clean_governments <- governments |> 
  clean_names() |> 
  remove_empty(which = c("cols", "rows"))
```
```{r save-data-check}
grade_this_code()
```

## Inconsistency

Janitor also has some handy tools for our data smells. One is called `tabyl`, which creates a table of unique records in a single field. All you need to do is feed the column name to `tabyl` and it'll do the rest.

### Exercise 3: Data smells with tabyl

So does the Census Bureau record the names of governments consistently? `tabyl` will tell us and will tell us a little bit about the data. Remember: we've cleaned the headers, so it's now `name_of_government`

```{r tabyl1-data, exercise=TRUE, exercise.setup = "load-data"}
clean_governments |> tabyl(____)
```
```{r tabyl1-data-solution, exercise.reveal_solution = FALSE}
clean_governments |> tabyl(name_of_government)
```
```{r tabyl1-data-check}
grade_this_code()
```

What you are looking for here are mistakes. For a made up example: Let's pretend you had a town named Adams. Do you see Adams and then ADAMS? There's a chance that's a mistake. There's also a chance one is a county and one is a city. There's a chance you might have two different levels of government called that. Data smells are just a warning -- they aren't a guarantee of problems.

### Exercise 4: Combining what we know

What if you had a legislative candidate complaining about how expensive running the jails had become? We can add a `filter` before we run `tabyl` to give specific data the smell test. To find jails (and prisons), we want to filter the `government_function` column for Corrections. Then, we can run tabyl on the name of the government to see what we get with that. 

```{r tabyl2-data, exercise=TRUE, exercise.setup = "load-data"}
clean_governments |> 
  filter(____ == "____") |> 
  tabyl(____)
```
```{r tabyl2-data-solution, exercise.reveal_solution = FALSE}
clean_governments |> 
  filter(government_function == "Corrections") |> 
  tabyl(name_of_government)
```
```{r tabyl2-data-check}
grade_this_code()
```

Depending on how your state is set up, you might see one row for your state corrections organization -- probably under your state's name -- and one row for each county or parish jail. If you see an `n` column with a number other than 1, that's an immediate question you'll need to answer before you start doing data analysis. 

## The Recap

Throughout this lesson, you've learned several key data cleaning techniques using the janitor package. You've practiced cleaning column names with clean_names(), removing empty rows and columns with remove_empty(), and exploring data consistency with tabyl(). Remember, data cleaning is an essential step in any data analysis project, and the tools you've learned here will help you tackle common data issues more efficiently. As you work with different datasets, you'll find these janitor functions invaluable for quickly standardizing and exploring your data before diving into deeper analysis.

## Terms to Know

- `janitor`: An R package designed to simplify data cleaning tasks.
- `clean_names()`: A janitor function that standardizes column names to lowercase, removes spaces and special characters.
- `remove_empty()`: A janitor function that removes empty rows, columns, or both from a dataset.
- `tabyl()`: A janitor function that creates a frequency table of unique values in a column.
- Data cleaning: The process of identifying and correcting errors or inconsistencies in datasets.
- Duplicates: Multiple identical records in a dataset that may skew analysis results.
- Data consistency: The uniformity and reliability of data across a dataset.
